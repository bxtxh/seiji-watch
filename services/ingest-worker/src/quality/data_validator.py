"""
T53 Data Quality Validation Module
Validates data quality for pilot dataset generated by T52
"""
import logging
import re
from dataclasses import dataclass
from datetime import datetime
from typing import Any

logger = logging.getLogger(__name__)


@dataclass
class QualityMetric:
    """Individual quality metric result"""
    name: str
    value: float
    threshold: float
    passed: bool
    description: str
    recommendations: list[str]


@dataclass
class ValidationResult:
    """Overall validation result"""
    component: str
    metrics: list[QualityMetric]
    overall_score: float
    passed: bool
    summary: str


class DataQualityValidator:
    """Main data quality validation class"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # Quality thresholds
        self.thresholds = {
            'completeness': 0.95,  # 95% of records should be complete
            'consistency': 0.90,   # 90% consistency in data formats
            'accuracy': 0.85,      # 85% accuracy for parsed data
            'uniqueness': 0.98,    # 98% unique records (minimal duplicates)
            'timeliness': 0.80,    # 80% of data should be recent/relevant
            'validity': 0.90       # 90% of data should pass validation rules
        }

    def validate_pilot_dataset(
            self, pilot_data: dict[str, Any]) -> list[ValidationResult]:
        """Validate the complete pilot dataset"""
        results = []

        # Validate bills data
        if 'bills' in pilot_data.get('pilot_dataset', {}):
            bills_result = self.validate_bills_data(
                pilot_data['pilot_dataset']['bills'])
            results.append(bills_result)

        # Validate voting data
        if 'voting_sessions' in pilot_data.get('pilot_dataset', {}):
            voting_result = self.validate_voting_data(
                pilot_data['pilot_dataset']['voting_sessions'])
            results.append(voting_result)

        # Validate metadata
        metadata_result = self.validate_metadata(pilot_data)
        results.append(metadata_result)

        return results

    def validate_bills_data(self, bills: list[dict[str, Any]]) -> ValidationResult:
        """Validate bills data quality"""
        metrics = []

        # Completeness check
        complete_records = sum(1 for bill in bills if self._is_bill_complete(bill))
        completeness_score = complete_records / len(bills) if bills else 0

        metrics.append(
            QualityMetric(
                name="completeness",
                value=completeness_score,
                threshold=self.thresholds['completeness'],
                passed=completeness_score >= self.thresholds['completeness'],
                description=f"{complete_records}/{len(bills)} bills have all required fields",
                recommendations=self._get_completeness_recommendations(completeness_score)))

        # Uniqueness check
        unique_ids = set(bill.get('bill_id', '') for bill in bills)
        uniqueness_score = len(unique_ids) / len(bills) if bills else 0

        metrics.append(QualityMetric(
            name="uniqueness",
            value=uniqueness_score,
            threshold=self.thresholds['uniqueness'],
            passed=uniqueness_score >= self.thresholds['uniqueness'],
            description=f"{len(unique_ids)} unique bills out of {len(bills)} total",
            recommendations=self._get_uniqueness_recommendations(uniqueness_score)
        ))

        # Validity check (format validation)
        valid_records = sum(1 for bill in bills if self._is_bill_valid(bill))
        validity_score = valid_records / len(bills) if bills else 0

        metrics.append(QualityMetric(
            name="validity",
            value=validity_score,
            threshold=self.thresholds['validity'],
            passed=validity_score >= self.thresholds['validity'],
            description=f"{valid_records}/{len(bills)} bills pass format validation",
            recommendations=self._get_validity_recommendations(validity_score)
        ))

        # Title quality check
        title_quality_score = self._assess_title_quality(bills)

        metrics.append(QualityMetric(
            name="title_quality",
            value=title_quality_score,
            threshold=0.80,
            passed=title_quality_score >= 0.80,
            description=f"Title quality score: {title_quality_score:.2f}",
            recommendations=self._get_title_quality_recommendations(title_quality_score)
        ))

        # Category distribution check
        category_diversity_score = self._assess_category_diversity(bills)

        metrics.append(QualityMetric(
            name="category_diversity",
            value=category_diversity_score,
            threshold=0.60,
            passed=category_diversity_score >= 0.60,
            description=f"Category diversity score: {category_diversity_score:.2f}",
            recommendations=self._get_category_recommendations(category_diversity_score)
        ))

        # Calculate overall score
        overall_score = sum(m.value for m in metrics) / len(metrics)
        passed = all(m.passed for m in metrics)

        return ValidationResult(
            component="bills_data",
            metrics=metrics,
            overall_score=overall_score,
            passed=passed,
            summary=f"Bills data quality: {overall_score:.2f} ({'PASS' if passed else 'FAIL'})")

    def validate_voting_data(
            self, voting_sessions: list[dict[str, Any]]) -> ValidationResult:
        """Validate voting data quality"""
        metrics = []

        # Completeness check
        complete_sessions = sum(
            1 for session in voting_sessions if self._is_voting_session_complete(session))
        completeness_score = complete_sessions / \
            len(voting_sessions) if voting_sessions else 0

        metrics.append(
            QualityMetric(
                name="completeness",
                value=completeness_score,
                threshold=self.thresholds['completeness'],
                passed=completeness_score >= self.thresholds['completeness'],
                description=f"{complete_sessions}/{len(voting_sessions)} sessions have complete data",
                recommendations=self._get_voting_completeness_recommendations(completeness_score)))

        # Vote record consistency
        consistency_score = self._assess_vote_record_consistency(voting_sessions)

        metrics.append(
            QualityMetric(
                name="vote_consistency",
                value=consistency_score,
                threshold=0.90,
                passed=consistency_score >= 0.90,
                description=f"Vote record consistency: {consistency_score:.2f}",
                recommendations=self._get_vote_consistency_recommendations(consistency_score)))

        # Member data quality
        member_quality_score = self._assess_member_data_quality(voting_sessions)

        metrics.append(QualityMetric(
            name="member_data_quality",
            value=member_quality_score,
            threshold=0.85,
            passed=member_quality_score >= 0.85,
            description=f"Member data quality: {member_quality_score:.2f}",
            recommendations=self._get_member_data_recommendations(member_quality_score)
        ))

        # Party distribution
        party_diversity_score = self._assess_party_diversity(voting_sessions)

        metrics.append(
            QualityMetric(
                name="party_diversity",
                value=party_diversity_score,
                threshold=0.70,
                passed=party_diversity_score >= 0.70,
                description=f"Party diversity score: {party_diversity_score:.2f}",
                recommendations=self._get_party_diversity_recommendations(party_diversity_score)))

        # Calculate overall score
        overall_score = sum(m.value for m in metrics) / len(metrics)
        passed = all(m.passed for m in metrics)

        return ValidationResult(
            component="voting_data",
            metrics=metrics,
            overall_score=overall_score,
            passed=passed,
            summary=f"Voting data quality: {overall_score:.2f} ({'PASS' if passed else 'FAIL'})")

    def validate_metadata(self, pilot_data: dict[str, Any]) -> ValidationResult:
        """Validate metadata and execution info"""
        metrics = []

        # Execution info completeness
        exec_info = pilot_data.get('execution_info', {})
        metadata_completeness = self._assess_metadata_completeness(exec_info)

        metrics.append(QualityMetric(
            name="metadata_completeness",
            value=metadata_completeness,
            threshold=0.90,
            passed=metadata_completeness >= 0.90,
            description=f"Metadata completeness: {metadata_completeness:.2f}",
            recommendations=self._get_metadata_recommendations(metadata_completeness)
        ))

        # Processing performance
        duration = exec_info.get('duration_seconds', 0)
        performance_score = 1.0 if duration > 0 and duration < 10 else 0.5

        metrics.append(
            QualityMetric(
                name="processing_performance",
                value=performance_score,
                threshold=0.70,
                passed=performance_score >= 0.70,
                description=f"Processing time: {duration:.2f}s",
                recommendations=self._get_performance_recommendations(
                    performance_score,
                    duration)))

        # Data freshness
        timestamp = exec_info.get('timestamp', '')
        freshness_score = self._assess_data_freshness(timestamp)

        metrics.append(QualityMetric(
            name="data_freshness",
            value=freshness_score,
            threshold=0.80,
            passed=freshness_score >= 0.80,
            description=f"Data freshness score: {freshness_score:.2f}",
            recommendations=self._get_freshness_recommendations(freshness_score)
        ))

        # Calculate overall score
        overall_score = sum(m.value for m in metrics) / len(metrics)
        passed = all(m.passed for m in metrics)

        return ValidationResult(
            component="metadata",
            metrics=metrics,
            overall_score=overall_score,
            passed=passed,
            summary=f"Metadata quality: {overall_score:.2f} ({'PASS' if passed else 'FAIL'})")

    # Helper methods for validation logic

    def _is_bill_complete(self, bill: dict[str, Any]) -> bool:
        """Check if bill has all required fields"""
        required_fields = ['bill_id', 'title', 'status', 'category']
        return all(bill.get(field) for field in required_fields)

    def _is_bill_valid(self, bill: dict[str, Any]) -> bool:
        """Check if bill data follows expected formats"""
        # Check bill ID format (should be like "217-1")
        bill_id = bill.get('bill_id', '')
        if not re.match(r'^\d+-\d+$', bill_id):
            return False

        # Check title length (should be reasonable)
        title = bill.get('title', '')
        if len(title) < 5 or len(title) > 200:
            return False

        # Check category is valid
        valid_categories = ['税制', 'その他', '経済・産業', '予算・決算', '社会保障', '外交・国際']
        category = bill.get('category', '')
        if category not in valid_categories:
            return False

        return True

    def _assess_title_quality(self, bills: list[dict[str, Any]]) -> float:
        """Assess quality of bill titles"""
        if not bills:
            return 0.0

        quality_scores = []
        for bill in bills:
            title = bill.get('title', '')
            score = 0.0

            # Length check (reasonable length)
            if 10 <= len(title) <= 100:
                score += 0.3

            # Contains Japanese characters
            if any(ord(char) > 127 for char in title):
                score += 0.3

            # Not just symbols or numbers
            if re.search(r'[ひらがなカタカナ漢字]', title):
                score += 0.4

            quality_scores.append(score)

        return sum(quality_scores) / len(quality_scores)

    def _assess_category_diversity(self, bills: list[dict[str, Any]]) -> float:
        """Assess diversity of bill categories"""
        if not bills:
            return 0.0

        categories = [bill.get('category', '') for bill in bills]
        unique_categories = set(categories)

        # Score based on diversity (more categories = better)
        diversity_ratio = len(unique_categories) / len(categories)
        max_possible_categories = 6  # Based on known categories
        coverage_ratio = len(unique_categories) / max_possible_categories

        return (diversity_ratio + coverage_ratio) / 2

    def _is_voting_session_complete(self, session: dict[str, Any]) -> bool:
        """Check if voting session has complete data"""
        required_fields = ['bill_number', 'bill_title', 'vote_date', 'vote_records']
        return all(session.get(field) for field in required_fields)

    def _assess_vote_record_consistency(
            self, voting_sessions: list[dict[str, Any]]) -> float:
        """Assess consistency of vote records"""
        if not voting_sessions:
            return 0.0

        consistency_scores = []
        for session in voting_sessions:
            vote_records = session.get('vote_records', [])
            if not vote_records:
                consistency_scores.append(0.0)
                continue

            # Check for consistent fields across records
            required_fields = ['member_name', 'party_name', 'vote_result']
            complete_records = sum(
                1 for record in vote_records if all(
                    record.get(field) for field in required_fields))

            consistency_score = complete_records / len(vote_records)
            consistency_scores.append(consistency_score)

        return sum(consistency_scores) / len(consistency_scores)

    def _assess_member_data_quality(
            self, voting_sessions: list[dict[str, Any]]) -> float:
        """Assess quality of member data"""
        if not voting_sessions:
            return 0.0

        all_members = []
        for session in voting_sessions:
            vote_records = session.get('vote_records', [])
            all_members.extend(vote_records)

        if not all_members:
            return 0.0

        quality_scores = []
        for member in all_members:
            score = 0.0

            # Has member name
            if member.get('member_name'):
                score += 0.4

            # Has party affiliation
            if member.get('party_name'):
                score += 0.3

            # Has valid vote result
            valid_votes = ['賛成', '反対', '棄権', '欠席']
            if member.get('vote_result') in valid_votes:
                score += 0.3

            quality_scores.append(score)

        return sum(quality_scores) / len(quality_scores)

    def _assess_party_diversity(self, voting_sessions: list[dict[str, Any]]) -> float:
        """Assess diversity of political parties"""
        if not voting_sessions:
            return 0.0

        all_parties = set()
        for session in voting_sessions:
            vote_records = session.get('vote_records', [])
            for record in vote_records:
                party = record.get('party_name', '')
                if party:
                    all_parties.add(party)

        # Score based on number of parties (more = better representation)
        # Typical Diet has 10+ parties, so normalize accordingly
        party_count = len(all_parties)
        max_expected_parties = 12

        return min(party_count / max_expected_parties, 1.0)

    def _assess_metadata_completeness(self, exec_info: dict[str, Any]) -> float:
        """Assess completeness of execution metadata"""
        required_fields = ['timestamp', 'execution_type', 'duration_seconds']
        present_fields = sum(1 for field in required_fields if exec_info.get(field))

        return present_fields / len(required_fields)

    def _assess_data_freshness(self, timestamp_str: str) -> float:
        """Assess how fresh/recent the data is"""
        if not timestamp_str:
            return 0.0

        try:
            timestamp = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
            now = datetime.now()

            # Data is fresh if collected within last 24 hours
            hours_old = (now - timestamp).total_seconds() / 3600
            if hours_old <= 1:
                return 1.0
            elif hours_old <= 24:
                return 0.8
            elif hours_old <= 168:  # 1 week
                return 0.6
            else:
                return 0.3
        except Exception:
            return 0.0

    # Recommendation methods

    def _get_completeness_recommendations(self, score: float) -> list[str]:
        """Get recommendations for improving completeness"""
        if score >= 0.95:
            return [
                "Excellent completeness - maintain current data collection standards"
            ]
        elif score >= 0.80:
            return [
                "Good completeness - verify required fields in data collection pipeline"
            ]
        else:
            return [
                "Low completeness - review data extraction logic",
                "Add validation checks during data collection",
                "Implement fallback data sources for missing fields"
            ]

    def _get_uniqueness_recommendations(self, score: float) -> list[str]:
        """Get recommendations for improving uniqueness"""
        if score >= 0.98:
            return ["Excellent uniqueness - no duplicate detection issues"]
        else:
            return [

                "Implement duplicate detection during data collection",
                "Add unique constraints to data storage",
                "Review bill ID generation logic"

            ]

    def _get_validity_recommendations(self, score: float) -> list[str]:
        """Get recommendations for improving validity"""
        if score >= 0.90:
            return ["Good format validation - maintain current standards"]
        else:
            return [
                "Strengthen data format validation rules",
                "Add input sanitization for scraped content",
                "Implement schema validation for structured data"
            ]

    def _get_title_quality_recommendations(self, score: float) -> list[str]:
        """Get recommendations for improving title quality"""
        if score >= 0.80:
            return ["Good title quality - content extraction working well"]
        else:
            return [
                "Review title extraction logic from source pages",
                "Add content cleaning for extracted titles",
                "Implement title validation rules"
            ]

    def _get_category_recommendations(self, score: float) -> list[str]:
        """Get recommendations for improving category diversity"""
        if score >= 0.60:
            return ["Good category coverage - classification working well"]
        else:
            return [
                "Expand bill categorization logic",
                "Add more category keywords for classification",
                "Review category assignment algorithm"
            ]

    def _get_voting_completeness_recommendations(self, score: float) -> list[str]:
        """Get recommendations for voting data completeness"""
        if score >= 0.95:
            return ["Excellent voting data completeness"]
        else:
            return [
                "Review voting data extraction logic",
                "Add validation for required voting session fields",
                "Implement fallback for missing vote records"
            ]

    def _get_vote_consistency_recommendations(self, score: float) -> list[str]:
        """Get recommendations for vote record consistency"""
        if score >= 0.90:
            return ["Good vote record consistency"]
        else:
            return [
                "Standardize vote record field extraction",
                "Add validation for member data fields",
                "Implement data cleaning for vote results"
            ]

    def _get_member_data_recommendations(self, score: float) -> list[str]:
        """Get recommendations for member data quality"""
        if score >= 0.85:
            return ["Good member data quality"]
        else:
            return [

                "Improve member name extraction accuracy",
                "Add party affiliation validation",
                "Standardize vote result values"

            ]

    def _get_party_diversity_recommendations(self, score: float) -> list[str]:
        """Get recommendations for party diversity"""
        if score >= 0.70:
            return ["Good party representation in voting data"]
        else:
            return [

                "Verify all parties are being captured in vote records",
                "Review party name standardization",
                "Ensure comprehensive voting session coverage"

            ]

    def _get_metadata_recommendations(self, score: float) -> list[str]:
        """Get recommendations for metadata completeness"""
        if score >= 0.90:
            return ["Good metadata tracking"]
        else:
            return [

                "Add missing execution metadata fields",
                "Implement comprehensive logging",
                "Track additional performance metrics"

            ]

    def _get_performance_recommendations(
            self, score: float, duration: float) -> list[str]:
        """Get recommendations for processing performance"""
        if score >= 0.70:
            return ["Good processing performance"]
        else:
            recommendations = ["Optimize data processing pipeline"]
            if duration > 10:
                recommendations.append(
                    "Consider parallel processing for large datasets")
            if duration > 60:
                recommendations.append(
                    "Implement batch processing with progress tracking")
            return recommendations

    def _get_freshness_recommendations(self, score: float) -> list[str]:
        """Get recommendations for data freshness"""
        if score >= 0.80:
            return ["Data is sufficiently fresh"]
        else:
            return [

                "Implement more frequent data collection",
                "Add real-time data update mechanisms",
                "Monitor data source update frequency"

            ]
