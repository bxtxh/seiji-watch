#!/usr/bin/env python3
"""
Notes ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰æ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¸ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œã—ãŸå°‚ç”¨ãƒ‘ãƒ¼ã‚µãƒ¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç§»è¡Œ
"""

import os
import re
import sys
import time
from dataclasses import dataclass
from pathlib import Path

import requests


@dataclass
class BillData:
    """æ³•æ¡ˆãƒ‡ãƒ¼ã‚¿æ§‹é€ """
    bill_id: str | None = None
    status: str | None = None
    category: str | None = None
    submitter: str | None = None
    url: str | None = None
    stage: str | None = None
    house: str | None = None
    bill_type: str | None = None
    date: str | None = None
    data_source: str | None = None


class NotesPatternParser:
    """Notesãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.patterns = {
            'structured_emoji': self._parse_structured_emoji,
            'pipe_separated': self._parse_pipe_separated,
            'detailed_newline': self._parse_detailed_newline
        }

    def detect_pattern(self, notes: str) -> str:
        """Notesãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º"""
        if 'ã€æ³•æ¡ˆè©³ç´°ã€‘' in notes or 'ğŸ›ï¸' in notes:
            return 'structured_emoji'
        elif 'çŠ¶æ…‹:' in notes and 'ã‚«ãƒ†ã‚´ãƒª:' in notes and '\\n' in notes:
            return 'detailed_newline'
        elif ' | ' in notes:
            return 'pipe_separated'
        elif '\n' in notes and len(notes.split('\n')) > 3:
            return 'multiline_detailed'
        else:
            return 'unknown'

    def parse(self, notes: str) -> BillData:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ã¦Notesã‚’è§£æ"""
        pattern = self.detect_pattern(notes)

        if pattern in self.patterns:
            return self.patterns[pattern](notes)
        else:
            return BillData()  # ç©ºã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™

    def _parse_structured_emoji(self, notes: str) -> BillData:
        """æ§‹é€ åŒ–çµµæ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è§£æ"""
        data = BillData()

        # æ³•æ¡ˆID (ğŸ›ï¸ æ³•æ¡ˆID: 217-58)
        bill_id_match = re.search(r'ğŸ›ï¸ æ³•æ¡ˆID[:\s]*([^\n]+)', notes)
        if bill_id_match:
            data.bill_id = bill_id_match.group(1).strip()

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ (ğŸ“‹ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: è­°æ¡ˆè¦æ—¨)
        status_match = re.search(r'ğŸ“‹ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹[:\s]*([^\n]+)', notes)
        if status_match:
            status_value = status_match.group(1).strip()
            # çµµæ–‡å­—ã‚„æ®µéšæƒ…å ±ãŒæ··å…¥ã—ã¦ã„ã‚‹å ´åˆã¯ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if 'ğŸ”„ æ®µéš:' in status_value:
                status_value = status_value.split('ğŸ”„ æ®µéš:')[0].strip()
            # å¼•ç”¨ç¬¦ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            status_value = status_value.strip('"\'')
            data.status = status_value

        # æ®µéš (ğŸ”„ æ®µéš: Backlog)
        stage_match = re.search(r'ğŸ”„ æ®µéš[:\s]*([^\n]+)', notes)
        if stage_match:
            data.stage = stage_match.group(1).strip()

        # æå‡ºè€… (ğŸ‘¤ æå‡ºè€…: è­°å“¡)
        submitter_match = re.search(r'ğŸ‘¤ æå‡ºè€…[:\s]*([^\n]+)', notes)
        if submitter_match:
            data.submitter = submitter_match.group(1).strip()

        # ã‚«ãƒ†ã‚´ãƒª (ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒª: ãã®ä»–)
        category_match = re.search(r'ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒª[:\s]*([^\n]+)', notes)
        if category_match:
            data.category = category_match.group(1).strip()

        # URL (ğŸ”— URL: https://...)
        url_match = re.search(r'ğŸ”— URL[:\s]*([^\n]+)', notes)
        if url_match:
            data.url = url_match.group(1).strip()

        # åé›†æ—¥æ™‚ (ğŸ“… åé›†æ—¥æ™‚: 2025-07-09T03:22:37.753052)
        date_match = re.search(r'ğŸ“… åé›†æ—¥æ™‚[:\s]*([^\n]+)', notes)
        if date_match:
            data.date = date_match.group(1).strip()

        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
        if 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: å‚è­°é™¢å…¬å¼ã‚µã‚¤ãƒˆ' in notes:
            data.data_source = 'å‚è­°é™¢å…¬å¼ã‚µã‚¤ãƒˆ'

        return data

    def _parse_pipe_separated(self, notes: str) -> BillData:
        """ãƒ‘ã‚¤ãƒ—åŒºåˆ‡ã‚Šãƒ‘ã‚¿ãƒ¼ãƒ³ã®è§£æ"""
        data = BillData()

        # " | " ã§åˆ†å‰²
        parts = notes.split(' | ')

        for part in parts:
            part = part.strip()

            if 'çŠ¶æ…‹:' in part:
                data.status = part.replace('çŠ¶æ…‹:', '').strip().strip('"\'')
            elif 'ã‚«ãƒ†ã‚´ãƒª:' in part:
                data.category = part.replace('ã‚«ãƒ†ã‚´ãƒª:', '').strip().strip('"\'')
            elif 'æå‡ºè€…:' in part:
                data.submitter = part.replace('æå‡ºè€…:', '').strip().strip('"\'')
            elif part.startswith('http'):
                data.url = part.strip()

        return data

    def _parse_detailed_newline(self, notes: str) -> BillData:
        """è©³ç´°æ”¹è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã®è§£æ"""
        data = BillData()

        # \\n ã‚’å®Ÿéš›ã®æ”¹è¡Œã«å¤‰æ›
        notes = notes.replace('\\n', '\n')
        lines = notes.split('\n')

        for line in lines:
            line = line.strip()

            if line.startswith('çŠ¶æ…‹:'):
                data.status = line.replace('çŠ¶æ…‹:', '').strip().strip('"\'')
            elif line.startswith('ã‚«ãƒ†ã‚´ãƒª:'):
                data.category = line.replace('ã‚«ãƒ†ã‚´ãƒª:', '').strip().strip('"\'')
            elif line.startswith('æå‡ºè€…:'):
                data.submitter = line.replace('æå‡ºè€…:', '').strip().strip('"\'')
            elif line.startswith('URL:'):
                data.url = line.replace('URL:', '').strip()
            elif line.startswith('http'):
                data.url = line.strip()

        return data


class AirtableMigrator:
    """Airtableãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self, pat: str, base_id: str):
        self.pat = pat
        self.base_id = base_id
        self.base_url = f"https://api.airtable.com/v0/{base_id}"
        self.headers = {
            "Authorization": f"Bearer {pat}",
            "Content-Type": "application/json"}
        self.parser = NotesPatternParser()
        self.rate_limit_delay = 0.3  # 300ms between requests

    def _rate_limit(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ"""
        time.sleep(self.rate_limit_delay)

    def get_all_bills(self) -> list[dict]:
        """å…¨ã¦ã®æ³•æ¡ˆãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—"""
        url = f"{self.base_url}/Bills%20%28%E6%B3%95%E6%A1%88%29"
        all_records = []
        params = {"maxRecords": 100}

        while True:
            self._rate_limit()
            response = requests.get(url, headers=self.headers, params=params)

            if response.status_code != 200:
                print(f"âŒ API ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                break

            data = response.json()
            records = data.get('records', [])
            all_records.extend(records)

            offset = data.get('offset')
            if not offset:
                break
            params['offset'] = offset

        return all_records

    def analyze_migration_scope(self, records: list[dict]) -> dict:
        """ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç¯„å›²ã®åˆ†æ"""
        analysis = {
            'total_records': len(records),
            'notes_records': 0,
            'patterns': {
                'structured_emoji': 0,
                'pipe_separated': 0,
                'detailed_newline': 0,
                'other': 0},
            'extractable_fields': {
                'bill_id': 0,
                'status': 0,
                'category': 0,
                'submitter': 0,
                'url': 0},
            'records_to_migrate': []}

        for record in records:
            fields = record.get('fields', {})
            notes = fields.get('Notes', '')

            if notes:
                analysis['notes_records'] += 1
                pattern = self.parser.detect_pattern(notes)

                if pattern in analysis['patterns']:
                    analysis['patterns'][pattern] += 1
                else:
                    analysis['patterns']['other'] += 1

                # ãƒ‘ãƒ¼ã‚¹çµæœã‚’ãƒã‚§ãƒƒã‚¯
                parsed_data = self.parser.parse(notes)

                if parsed_data.bill_id:
                    analysis['extractable_fields']['bill_id'] += 1
                if parsed_data.status:
                    analysis['extractable_fields']['status'] += 1
                if parsed_data.category:
                    analysis['extractable_fields']['category'] += 1
                if parsed_data.submitter:
                    analysis['extractable_fields']['submitter'] += 1
                if parsed_data.url:
                    analysis['extractable_fields']['url'] += 1

                analysis['records_to_migrate'].append({
                    'record_id': record['id'],
                    'name': fields.get('Name', 'N/A'),
                    'pattern': pattern,
                    'parsed_data': parsed_data
                })

        return analysis

    def update_record(
            self,
            record_id: str,
            fields_to_update: dict,
            dry_run: bool = True) -> bool:
        """ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°ï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å¯¾å¿œï¼‰"""
        if dry_run:
            print(f"  [DRY RUN] ãƒ¬ã‚³ãƒ¼ãƒ‰ {record_id} ã‚’æ›´æ–°äºˆå®š: {fields_to_update}")
            return True

        url = f"{self.base_url}/Bills%20%28%E6%B3%95%E6%A1%88%29/{record_id}"
        data = {"fields": fields_to_update}

        self._rate_limit()
        response = requests.patch(url, headers=self.headers, json=data)

        if response.status_code == 200:
            return True
        else:
            print(f"âŒ ãƒ¬ã‚³ãƒ¼ãƒ‰æ›´æ–°å¤±æ•— {record_id}: {response.status_code}")
            print(f"   ã‚¨ãƒ©ãƒ¼è©³ç´°: {response.text}")
            return False

    def migrate_record(self, record_info: dict, dry_run: bool = True) -> bool:
        """å€‹åˆ¥ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ¨©é™ã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰"""
        parsed_data = record_info['parsed_data']
        fields_to_update = {}

        # ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šï¼ˆæ¨©é™å•é¡ŒãŒèµ·ãã‚„ã™ã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é™¤å¤–ï¼‰
        safe_field_mapping = {
            'category': 'Category',
            'submitter': 'Submitter',
            'url': 'Bill_URL',
            'stage': 'Stage',
            'house': 'House',
            'bill_type': 'Bill_Type'
        }

        # æ›´æ–°ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æº–å‚™ï¼ˆå®‰å…¨ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿ï¼‰
        for field_name, airtable_field in safe_field_mapping.items():
            value = getattr(parsed_data, field_name)
            if value and value != 'N/A':
                fields_to_update[airtable_field] = value

        # bill_idã¯ç‰¹åˆ¥å‡¦ç†ï¼ˆBill_Numberã¾ãŸã¯Bill_IDãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ï¼‰
        if parsed_data.bill_id and parsed_data.bill_id != 'N/A':
            fields_to_update['Bill_Number'] = parsed_data.bill_id

        # data_sourceãŒã‚ã‚‹å ´åˆ
        if parsed_data.data_source:
            fields_to_update['Data_Source'] = parsed_data.data_source

        # Bill_Statusã¯æ¨©é™ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã‚„ã™ã„ãŸã‚ã€åˆ¥é€”å‡¦ç†
        # ã¾ãšå®‰å…¨ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§æ›´æ–°ã‚’è©¦ã¿ã€ãã®å¾Œå¿…è¦ã«å¿œã˜ã¦Bill_Statusã‚’è¿½åŠ 
        if fields_to_update:
            return self.update_record(
                record_info['record_id'], fields_to_update, dry_run)

        return True

    def execute_migration(self, dry_run: bool = True) -> dict:
        """ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        print("ğŸš€ Notes â†’ æ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
        print("=" * 60)

        # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—
        print("ğŸ“„ Step 1: ãƒ‡ãƒ¼ã‚¿å–å¾—")
        records = self.get_all_bills()
        print(f"âœ… {len(records)}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—")

        # 2. åˆ†æ
        print("\nğŸ” Step 2: ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç¯„å›²åˆ†æ")
        analysis = self.analyze_migration_scope(records)

        print(f"  ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {analysis['total_records']}ä»¶")
        print(f"  Notesã‚ã‚Šãƒ¬ã‚³ãƒ¼ãƒ‰: {analysis['notes_records']}ä»¶")
        print("  ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†å¸ƒ:")
        for pattern, count in analysis['patterns'].items():
            print(f"    {pattern}: {count}ä»¶")
        print("  æŠ½å‡ºå¯èƒ½ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:")
        for field, count in analysis['extractable_fields'].items():
            print(f"    {field}: {count}ä»¶")

        # 3. ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        mode = "ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³" if dry_run else "æœ¬å®Ÿè¡Œ"
        print(f"\nâš¡ Step 3: ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³{mode}")

        success_count = 0
        error_count = 0

        for record_info in analysis['records_to_migrate']:
            pattern = record_info['pattern']
            name = record_info['name'][:50]

            print(f"  å‡¦ç†ä¸­: {name}... ({pattern})")

            if self.migrate_record(record_info, dry_run):
                success_count += 1
            else:
                error_count += 1

        # 4. çµæœã‚µãƒãƒªãƒ¼
        print("\nğŸ“Š ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ")
        print(f"  æˆåŠŸ: {success_count}ä»¶")
        print(f"  å¤±æ•—: {error_count}ä»¶")

        if dry_run:
            print("\nâš ï¸  ã“ã‚Œã¯ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ã§ã™ã€‚å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã¯å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            print("    å®Ÿè¡Œã™ã‚‹ã«ã¯ --execute ãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")

        return {
            'success_count': success_count,
            'error_count': error_count,
            'analysis': analysis
        }


def load_env_file(env_file_path):
    if not os.path.exists(env_file_path):
        return False

    with open(env_file_path) as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                value = value.strip('"\'')
                os.environ[key] = value
    return True


def main():
    import argparse

    parser = argparse.ArgumentParser(description='Notes ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰æ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¸ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³')
    parser.add_argument(
        '--execute',
        action='store_true',
        help='å®Ÿéš›ã«ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰')
    parser.add_argument(
        '--pattern',
        choices=[
            'structured_emoji',
            'pipe_separated',
            'detailed_newline',
            'all'],
        default='all',
        help='å‡¦ç†ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŒ‡å®š')

    args = parser.parse_args()

    # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
    env_file = Path(__file__).parent / ".env.local"
    load_env_file(env_file)

    pat = os.environ.get('AIRTABLE_PAT')
    base_id = os.environ.get('AIRTABLE_BASE_ID')

    if not pat or not base_id:
        print("âŒ ç’°å¢ƒå¤‰æ•°ä¸è¶³: AIRTABLE_PAT, AIRTABLE_BASE_ID ãŒå¿…è¦ã§ã™")
        return 1

    # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    migrator = AirtableMigrator(pat, base_id)

    try:
        result = migrator.execute_migration(dry_run=not args.execute)
        return 0 if result['error_count'] == 0 else 1

    except Exception as e:
        print(f"âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
